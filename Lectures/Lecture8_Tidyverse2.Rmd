---
title: "Lecture 8: Tidverse2"
author: "Kelly and Gallego"
date: ''
output:
  html_document: default
  pdf_document: default
---

```{r, include = F}
library(knitr)
options(width=60)
require(knitr)
# Set so that long lines in R will be wrapped:
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE, message = F, warning = F, error = T, echo = T)
library(tidyverse)
library(lubridate)
library(yarrr)
```

# Reshaping Datasets: `gather` and `spread`

Very often you have a dataset of one shape, and you want to somehow magically change it into a different shape. For example, you have this:

```{r, echo = F}

head(mtcars[,1:3])

```

... but you want this:

```{r, echo = F}

t(head(mtcars[,1:3]))

```

... or this:

```{r, echo = F}

head(mtcars[,1:3]) %>% 
  rownames_to_column("Model") %>% 
  gather(key = "Measurement", value = "Value", -Model)

```

**R** -- and particularly the tidyverse -- is pretty good at reshaping dataframes once you get the hang of it. 

* The most basic transformation for a dataframe is `t()` (in base-**R**), which just transposes rows into columns and vice-versa.  That's what we did from the first to the second examples above. 

* Wide vs. Long.  You've heard us talk about wide and long tables... in general, tidy data analysis likes long tables with very few columns (see the table directly above), and organizing data in this way makes it easy to do plotting in ggplot. BUT long tables don't really make sense for humans to read off the screen (compare the first and third tables above... which would you rather read?)

It takes a while to get comfortable with these tidyverse commands, but they are super useful: `gather` makes a dataframe longer, and `spread` makes it wider. They are opposites of one another.

So: 

```{r}
Cars <- head(mtcars[,1:3]) #make a small dataset to play with

Cars

#this has rownames, which we have to get rid of before we use `gather()`

Cars %>% 
  rownames_to_column("Model") %>%    #here, move rownames to a column and call that column `Model`
  gather(#gather takes a few arguments, none of them intuitive:
    key = "ThingMeasured",  #the `key` will be the column header containing the newly organized info
    value = "Value",   #value is the measured value of the variable in the new column `ThingMeasured`
    -Model #and here, we're telling **R** NOT to gather the new column `Model` into `ThingMeasured`; we want it to be treated differently, and we denote that with a minus sign
  ) -> TidyCars  #create a new object called `TidyCars`

TidyCars

#then, to reverse this process, use `spread`:

spread(TidyCars, key = "ThingMeasured", value = "Value")


```

Note that long tables are useful for ggplot, as mentioned. This is because the different values in the "key" column (here, called `ThingsMeasured`) lend themselves to facet wrapping (and, outside of ggplot, also to `group_by` and subsequent analyses).

```{r}
ggplot(TidyCars, aes(x = Model, y = Value)) +
  geom_point() +
  facet_wrap(~ThingMeasured, scales = "free") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) #rotate x-axis labels
```


## Things Change... 

As **R** and the tidyverse grow and mature, things change. Surprisingly fast, in some cases. So now (as of September 2019) there are newly preferred ways of making your data longer or wider in the tidyverse.  

`pivot_longer()` is the new `gather()`.  According to 

https://tidyr.tidyverse.org/reference/pivot_longer.html : 

``pivot_longer() is an updated approach to gather(), designed to be both simpler to use and to handle more use cases. We recommend you use pivot_longer() for new code; gather() isn't going away but is no longer under active development.''

`pivot_wider()` is the new `spread`.  Sigh. But it's pretty much the same thing.

```{r}

Cars %>% 
  rownames_to_column("Model") %>%
  pivot_longer(cols = c(mpg, cyl, disp), 
               names_to = "ThingMeasured")


```





# Merging and Joining

Another common requirement is merging two datasets together... for example, admissions data for grad school (where data from each year are on a separate spreadsheet), etc. 

In one sense this can be a trivial task: where you are joining two dataframes with the exact same rows/columns, so you can just stick them together:

In base-**R**, `rbind` binds dataframes by rows (i.e., for dataframes with identical columns), and `cbind` does the same thing by columns (e.g., for dataframes with equal numbers of rows).

Tidyverse functions do the same with `bind_rows` and `bind_cols`.


```{r}

# in base-R
rbind(
  Cars[1:3,],
  Cars[4:6,]
)

#in tidyverse:

bind_rows(
  Cars[1:3,],
  Cars[4:6,]
)  #note here if you want the model names, you'd have to preserve rownames with a function like `rownames_to_column()`
```

But life is more complicated than that.  Normally you have something like this, in which one column is consistent between two different datasets: 

```{r, echo = F}
Cars <-
  Cars %>% 
  rownames_to_column("Model")
  
Cars1 <- Cars[1:2, 1:3]
Cars2 <- Cars[3:6, c(1,3:4)]
```

```{r, echo = T}
Cars1
Cars2

rbind(Cars1, Cars2)  #trying to do an rbind doesn't work because the column names are different... this is a safety check that makes sense. 

cbind(Cars1, Cars2)  #this weirdly does not give an error, but the output makes no sense.
```

So what to do?

```{r}
merge(Cars1, Cars2, all = T)  #base-R uses the `merge` function

full_join(Cars1, Cars2)  #tidyverse has a similar function `full_join`, and also `left_join`, `right_join`, `inner_join`, etc

```

Super useful. Note:

  - It uses column names to decide what to merge.  So the names have to be the same between datasets for this to work.  
  - It has some missing data, filled in with NA. You could then replace these values with real data, but you don't want the merge itself doing that for you, so this is a good thing.

(If you want to merge by rownames, create a new column from those names, and then use that column to merge the datasets.)




## Joins with *key* columns: relational tables

Sometimes the two datasets you want to share don't have the same columns: the information in both datasets is complementary. Let's go back to the library `nycflights13`. It has a number of datasets: 

  * flights
  
```{r flights}

library (nycflights13)

flights

```

  * airports

```{r airports}

airports

```

The information from both datasets is complementary, the only thing we need to combine both datasets is a common column that tells us which information from table2 can be joined with which row from table 1.

Here, the column called "faa" in `airports` is the same information as the column "origin" in `flights`.  So we can merge by those data, after telling R that these are secretly the same information: the name of the airport in question.

```{r}

joined.dataset <- left_join(flights, airports, 
                            by = c("origin" = "faa"))

#alternatively, you could have gotten the same answer like this:
airports %>% 
  rename("origin" = "faa") %>% 
  right_join(flights)

```
  
Note that `left_join` and `right_join` and their colleagues conceive of the join operation as somehow spatial.  For example, in `left_join(x, y)`, you are joining the dataframe `y` (on the right) into `x` (on the left). The result will be ``all rows from x, and all columns from x and y. Rows in x with no match in y will have NA values in the new columns.''
  
  
  
  
# `match` and `%in%`

While we're at it, these are some other super useful things, although they aren't in the tidyverse.  

Suppose we have two vectors: 

```{r, echo = T}

v1 <- c(letters[1:10])

v2 <- c(letters[8:15])

```




Base-**R** has great ways of:

  * finding out what elements of one vector are in another (`%in%`, which is a shorthand for another function, `is.element`), and 

  * reordering the elements of one vector to match those in another (using `match`, which finds the index of matching values between one vector and another).

```{r, echo = T}
match(v1, v2)  #NA means there is no match of v1 in v2.  A number is the INDEX of the matching value, rather than the value itself... here, the 8th element of v1 is the 1st element of v2, for example.

#note this is asymmetrical:
match(v2, v1)  #because the first element of v2 is the 8th element of v1




#the above give index values (the answer to the question `which element...`?)

#the below gives logical TRUE/FALSE (the answer to the question `is there any match...`?)

v1%in%v2  #gives a logical vector: is each element of v1 included in v2?  

#this is the same as 
is.element(v1, v2)

```


This is useful for, say, ordering rows of one dataset to match those in another dataset. 


```{r}

v1[match(v2,v1)]  #take the vector v1, and reorder it, so its elements match those in v2

```






OK... Lastly:

# Filtering vs. Subsetting

In base-**R**, subsetting can be a bit awkward.  Let's say -- in the `pirates` dataset -- you want to see only the pirates that are older than 40.  

```{r}
library(yarrr)

pirates[pirates$age > 40,]  #one option; select all rows for which pirates$age > 40

subset(pirates, pirates$age > 40)  #another option, same result

#the tidyverse version of this is `filter`.  I find this confusing because you are filtering and KEEPING rows that meet a set of criteria, rather than ELIMINATING them.  But whatever. 

pirates %>% 
  filter(age > 40)   #this does the same thing as subsetting, but a bit more elegantly.  And very useful for piping the result on to something else!



```








